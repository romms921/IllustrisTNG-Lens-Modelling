{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d428ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "30c50c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lens = 2 # Which lens is m assigned to\n",
    "m_param = 5 # Which parameter of that lens is m assigned to\n",
    "m = np.linspace(0.1, 1.0, 10)\n",
    "n_lens = 2\n",
    "n_param = 6\n",
    "n = np.linspace(0.1, 1.0, 10)\n",
    "o_lens = 1\n",
    "o_param = 8\n",
    "o = np.linspace(0.1, 1.0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c032720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ainsleylewis/Documents/Astronomy/IllustrisTNG Lens Modelling/System 2/'\n",
    "name = 'SIE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "51c27565",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('/Users/ainsleylewis/Documents/Astronomy/IllustrisTNG Lens Modelling/Simulations/input.py') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    # Find and Replace\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('path ='):\n",
    "            lines[i] = f\"path = '{path}/{name}'\\n\"\n",
    "        elif line.strip().startswith('constraint_file ='):\n",
    "            lines[i] = \"constraint_file = path + 'pos_point.dat'\\n\"\n",
    "    \n",
    "    # Find all occurrences of 'glafic.set_lens('\n",
    "    lens_lines = [i for i, line in enumerate(lines) if line.strip().startswith('glafic.set_lens(')]\n",
    "\n",
    "    # Modify the m, n, o values in the appropriate lens line\n",
    "    for lens_index, param_index, value in [(m_lens, m_param, m),\n",
    "                                        (n_lens, n_param, n),\n",
    "                                        (o_lens, o_param, o)]:\n",
    "        line_index = lens_lines[lens_index - 1]\n",
    "        line = lines[line_index]\n",
    "\n",
    "        # Extract content inside parentheses\n",
    "        inside = re.search(r'\\((.*)\\)', line).group(1)\n",
    "\n",
    "        # Split arguments\n",
    "        parts = [p.strip() for p in inside.split(',')]\n",
    "\n",
    "        # The first two arguments are: lens_id, 'model'\n",
    "        start_index = 2   # parameters start from index 2 (0-based)\n",
    "\n",
    "        # param_index is 1-based relative to *physical parameters* after the model\n",
    "        target_index = start_index + (param_index - 1)\n",
    "\n",
    "        if 0 <= target_index < len(parts):\n",
    "            parts[target_index] = str(value[0])\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: param_index {param_index} out of range for line:\\n{line}\")\n",
    "\n",
    "        # Rebuild the line\n",
    "        new_inside = ', '.join(parts)\n",
    "        lines[line_index] = re.sub(r'\\(.*\\)', f'({new_inside})', line)\n",
    "\n",
    "\n",
    "# Write back the modified lines\n",
    "with open('/Users/ainsleylewis/Documents/Astronomy/IllustrisTNG Lens Modelling/Simulations/input.py', 'w') as f:\n",
    "    f.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2f334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_params = ['$z_{s,fid}$', 'x', 'y', 'e', '$θ_{e}$', '$r_{Ein}$', '$\\gamma$ (PWI)']\n",
    "\n",
    "# SIE\n",
    "sie_params = ['$\\sigma$', 'x', 'y', 'e', '$θ_{e}$', '$r_{core}$', 'NaN']\n",
    "\n",
    "# NFW\n",
    "nfw_params = ['M', 'x', 'y', 'e', '$θ_{e}$', 'c or $r_{s}$', 'NaN']\n",
    "\n",
    "# EIN\n",
    "ein_params = ['M', 'x', 'y', 'e', '$θ_{e}$', 'c or $r_{s}$', r'$\\alpha_{e}$']\n",
    "\n",
    "# SHEAR \n",
    "shear_params = ['$z_{s,fid}$', 'x', 'y', '$\\gamma$', '$θ_{\\gamma}$', 'NaN', '$\\kappa$']\n",
    "\n",
    "# Sersic\n",
    "sersic_params = ['$M_{tot}$', 'x', 'y', 'e', '$θ_{e}$', '$r_{e}$', '$n$']\n",
    "\n",
    "# Cored SIE\n",
    "cored_sie_params = ['M', 'x', 'y', 'e', '$θ_{e}$', '$r_{core}$', 'NaN']\n",
    "\n",
    "# Multipoles\n",
    "mpole_params = ['$z_{s,fid}$', 'x', 'y', '$\\epsilon$', '$θ_{m}$', 'm', 'n']\n",
    "\n",
    "model_list = ['POW', 'SIE', 'ANFW', 'EIN', 'PERT', 'SERS', 'MPOLE']\n",
    "model_params = {\n",
    "    'POW': pow_params,\n",
    "    'SIE': sie_params,\n",
    "    'ANFW': nfw_params,\n",
    "    'EIN': ein_params,\n",
    "    'PERT': shear_params,\n",
    "    'SERS': sersic_params,\n",
    "    'MPOLE' : mpole_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "02758061",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_point_file = '/Users/ainsleylewis/Documents/Astronomy/IllustrisTNG Lens Modelling/obs_point/obs_point_(POS+FLUX).dat' \n",
    "input_py_file = '/Users/ainsleylewis/Documents/Astronomy/IllustrisTNG Lens Modelling/Simulations/input.py'  # Observation file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed750daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_extract(model_ver, model_path, constraint):\n",
    "    global pos_rms, mag_rms, chi2_value\n",
    "    # Load the data\n",
    "    with open(model_path + '/' + model_ver + '_optresult' + '.dat', 'r') as file:\n",
    "        opt_result = file.readlines()\n",
    "\n",
    "    # Find the last line with 'optimize' in it\n",
    "    last_optimize_index = None\n",
    "    for idx in range(len(opt_result) - 1, -1, -1):\n",
    "        if 'optimize' in opt_result[idx]:\n",
    "            last_optimize_index = idx\n",
    "            last_optimize_line = opt_result[idx]\n",
    "            break\n",
    "    if last_optimize_index is None:\n",
    "        raise ValueError(\"No line with 'optimize' found in the file.\")\n",
    "\n",
    "    # Extract everything after the last 'optimize' line\n",
    "    opt_result = opt_result[last_optimize_index + 1:]\n",
    "\n",
    "    # Count the number of lines that start with 'lens'\n",
    "    lens_count = sum(1 for line in opt_result if line.startswith('lens'))\n",
    "\n",
    "    # Initialize a dictionary to hold the lens parameters\n",
    "    lens_params_dict = {}\n",
    "\n",
    "    # Extract the lens parameters\n",
    "    lens_params = []\n",
    "    for line in opt_result:\n",
    "        if line.startswith('lens'):\n",
    "            parts = re.split(r'\\s+', line.strip())\n",
    "            lens_name = parts[1]\n",
    "            params = [float(x) for x in parts[2:]]\n",
    "\n",
    "            # Store the parameters in the dictionary\n",
    "            lens_params_dict[lens_name] = params\n",
    "            lens_params.append((lens_name, params))\n",
    "\n",
    "    # Remove the first lens parameter\n",
    "    if lens_params:\n",
    "        for i in range(len(lens_params)):\n",
    "            lens_name, params = lens_params[i]\n",
    "            lens_params_dict[lens_name] = params[1:]\n",
    "\n",
    "    # Extract the source parameters\n",
    "    source_params = []\n",
    "    for line in opt_result:\n",
    "        if line.startswith('point'):\n",
    "            parts = re.split(r'\\s+', line.strip())\n",
    "            params = [float(x) for x in parts[1:]]\n",
    "            source_params.append(params)\n",
    "    \n",
    "    # Extract the chi2 \n",
    "    chi2_line = next((line for line in opt_result if 'chi^2' in line), None)\n",
    "    if chi2_line is None:\n",
    "        raise ValueError(\"No line with 'chi2' found in the file.\")\n",
    "\n",
    "    chi2_value = float(chi2_line.split('=')[-1].strip().split()[0])\n",
    "    # print(f\"✅ Extracted chi2 value: {chi2_value}\")\n",
    "\n",
    "    # Number of len profiles\n",
    "    num_lens_profiles = len(lens_params_dict)\n",
    "\n",
    "    # Use generic column names: param1, param2, ...\n",
    "    df = pd.DataFrame()\n",
    "    rows = []\n",
    "    max_param_len = 0\n",
    "\n",
    "    for lens_name, params in lens_params_dict.items():\n",
    "        row = {'Lens Name': lens_name}\n",
    "        for i, val in enumerate(params):\n",
    "            row[f'param{i+1}'] = val\n",
    "        rows.append(row)\n",
    "        if len(params) > max_param_len:\n",
    "            max_param_len = len(params)\n",
    "\n",
    "    columns = ['Lens Name'] + [f'param{i+1}' for i in range(max_param_len)]\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    \n",
    "    # Load the input parameters from the Python file\n",
    "    with open(input_py_file, 'r') as file:\n",
    "        py = file.readlines()\n",
    "\n",
    "    # Extracting the input parameters from the Python file\n",
    "    set_lens_lines = [line for line in py if line.startswith('glafic.set_lens(')]\n",
    "    if not set_lens_lines:\n",
    "        raise ValueError(\"No lines starting with 'glafic.set_lens(' found in the file.\")\n",
    "\n",
    "    set_lens_params = []\n",
    "    for line in set_lens_lines:\n",
    "        match = re.search(r'set_lens\\((.*?)\\)', line)\n",
    "        if match:\n",
    "            params_str = match.group(1)\n",
    "            params = [param.strip() for param in params_str.split(',')]\n",
    "            set_lens_params.append(params)\n",
    "        else:\n",
    "            raise ValueError(f\"No valid parameters found in line: {line.strip()}\")\n",
    "\n",
    "    # Store the parameters in a dictionary\n",
    "    set_lens_dict = {}\n",
    "    for params in set_lens_params:\n",
    "        if len(params) < 3:\n",
    "            raise ValueError(f\"Not enough parameters found in line: {params}\")\n",
    "        lens_name = params[1].strip(\"'\\\"\")  # Remove quotes from lens name\n",
    "        lens_params = [float(x) for x in params[2:]]  # Skip index and lens name\n",
    "        set_lens_dict[lens_name] = lens_params\n",
    "\n",
    "    # Remove the first lens parameter\n",
    "    if set_lens_dict:\n",
    "        for lens_name, params in set_lens_dict.items():\n",
    "            set_lens_dict[lens_name] = params[1:]  # Remove the first parameter (index)\n",
    "\n",
    "    # Use generic column names: param1, param2, ...\n",
    "    df_input = pd.DataFrame()\n",
    "    rows_input = []\n",
    "    max_param_len_input = 0\n",
    "    for lens_name, params in set_lens_dict.items():\n",
    "        row = {'Lens Name': lens_name}\n",
    "        for i, val in enumerate(params):\n",
    "            row[f'param{i+1}'] = val\n",
    "        rows_input.append(row)\n",
    "        if len(params) > max_param_len_input:\n",
    "            max_param_len_input = len(params)\n",
    "    columns_input = ['Lens Name'] + [f'param{i+1}' for i in range(max_param_len_input)]\n",
    "    df_input = pd.DataFrame(rows_input, columns=columns_input)\n",
    "    \n",
    "    # Extract input flags from the Python file\n",
    "    set_flag_lines = [line for line in py if line.startswith('glafic.setopt_lens(')]\n",
    "    if not set_flag_lines:\n",
    "        raise ValueError(\"No lines starting with 'glafic.setopt_lens(' found in the file.\")\n",
    "    set_flag_params = []\n",
    "    for line in set_flag_lines:\n",
    "        match = re.search(r'setopt_lens\\((.*?)\\)', line)\n",
    "        if match:\n",
    "            params_str = match.group(1)\n",
    "            params = [param.strip() for param in params_str.split(',')]\n",
    "            set_flag_params.append(params)\n",
    "        else:\n",
    "            raise ValueError(f\"No valid parameters found in line: {line.strip()}\")\n",
    "    \n",
    "    # Store the parameters in a dictionary\n",
    "    set_flag_dict = {}\n",
    "    for params in set_flag_params:\n",
    "        if len(params) < 2:\n",
    "            raise ValueError(f\"Not enough parameters found in line: {params}\")\n",
    "        # The lens name is not present in setopt_lens, so use the lens index to map to set_lens_dict\n",
    "        lens_index = params[0].strip(\"'\\\"\")\n",
    "        # Find the lens name corresponding to this index from set_lens_params\n",
    "        lens_name = None\n",
    "        for lens_params in set_lens_params:\n",
    "            if lens_params[0].strip(\"'\\\"\") == lens_index:\n",
    "                lens_name = lens_params[1].strip(\"'\\\"\")\n",
    "                break\n",
    "        if lens_name is None:\n",
    "            raise ValueError(f\"Lens name for index {lens_index} not found in set_lens_params\")\n",
    "        flag = ','.join(params[1:])  # Join all flag values as a string\n",
    "        set_flag_dict[lens_name] = flag\n",
    "   \n",
    "    # Remove the first flag parameter\n",
    "    if set_flag_dict:\n",
    "        for lens_name, flag in set_flag_dict.items():\n",
    "            flag_parts = flag.split(',')\n",
    "            set_flag_dict[lens_name] = ','.join(flag_parts[1:])  # Remove the first flag parameter\n",
    "    \n",
    "    # Dynamically create columns: 'Lens Name', 'flag1', 'flag2', ..., based on the maximum number of flags\n",
    "    df_flag = pd.DataFrame()\n",
    "    rows_flag = []\n",
    "    max_flag_len = 0\n",
    "    \n",
    "    # First, determine the maximum number of flags\n",
    "    for flag in set_flag_dict.values():\n",
    "        flag_parts = flag.split(',')\n",
    "        if len(flag_parts) > max_flag_len:\n",
    "            max_flag_len = len(flag_parts)\n",
    "    for lens_name, flag in set_flag_dict.items():\n",
    "        flag_parts = flag.split(',')\n",
    "        row = {'Lens Name': lens_name}\n",
    "        for i, val in enumerate(flag_parts):\n",
    "            row[f'flag{i+1}'] = val\n",
    "        rows_flag.append(row)\n",
    "    columns_flag = ['Lens Name'] + [f'flag{i+1}' for i in range(max_flag_len)]  \n",
    "    df_flag = pd.DataFrame(rows_flag, columns=columns_flag)\n",
    "    \n",
    "    # Combine all dataframes into a list of dataframes for each lens\n",
    "    dfs = []\n",
    "    \n",
    "    for i in range(num_lens_profiles):\n",
    "        lens_name = df['Lens Name'][i]\n",
    "        \n",
    "        # Find the model type (case-insensitive match)\n",
    "        model_type = None\n",
    "        for m in model_list:\n",
    "            if m.lower() == lens_name.lower():\n",
    "                model_type = m\n",
    "                break\n",
    "        if model_type is None:\n",
    "            continue\n",
    "\n",
    "        symbols = model_params[model_type][:7]\n",
    "        # Row 2: input\n",
    "        row_input = pd.DataFrame([df_input.iloc[i, 1:8].values], columns=symbols)\n",
    "        # Row 3: output\n",
    "        row_output = pd.DataFrame([df.iloc[i, 1:8].values], columns=symbols)\n",
    "        # Row 4: flags\n",
    "        row_flags = pd.DataFrame([df_flag.iloc[i, 1:8].values], columns=symbols)\n",
    "\n",
    "        # Stack vertically, add a label column for row type\n",
    "        lens_df = pd.concat([\n",
    "            row_input.assign(Type='Input'),\n",
    "            row_output.assign(Type='Output'),\n",
    "            row_flags.assign(Type='Flag')\n",
    "        ], ignore_index=True)\n",
    "        lens_df.insert(0, 'Lens Name', lens_name)\n",
    "        \n",
    "        # Move 'Type' to the second column\n",
    "        cols = lens_df.columns.tolist()\n",
    "        cols.insert(1, cols.pop(cols.index('Type')))\n",
    "        lens_df = lens_df[cols]\n",
    "        dfs.append(lens_df)\n",
    "    \n",
    "    # Anomaly Calculation\n",
    "    columnn_names = ['x', 'y', 'mag', 'pos_err', 'mag_err', '1', '2', '3']\n",
    "    obs_point = pd.read_csv(obs_point_file, delim_whitespace=True, header=None, skiprows=1, names=columnn_names)\n",
    "    out_point = pd.read_csv(model_path + '/' + model_ver + '_point.dat', delim_whitespace=True, header=None, skiprows=1, names=columnn_names)\n",
    "    out_point.drop(columns=['mag_err', '1', '2', '3'], inplace=True)\n",
    "\n",
    "    # Drop rows in obs_point where the corresponding out_point['mag'] < 1\n",
    "    mask = abs(out_point['mag']) >= 1\n",
    "    out_point = out_point[mask[:len(out_point)]].reset_index(drop=True)\n",
    "    out_point['x_diff'] = abs(out_point['x'] - obs_point['x'])\n",
    "    out_point['y_diff'] = abs(out_point['y'] - obs_point['y'])\n",
    "    out_point['mag_diff'] = abs(abs(out_point['mag']) - abs(obs_point['mag']))\n",
    "    out_point['pos_sq'] = np.sqrt((out_point['x_diff']**2 + out_point['y_diff']**2).astype(float))  # Plotted on graph\n",
    "\n",
    "    # RMS\n",
    "    pos_rms = np.average(out_point['pos_sq'])\n",
    "\n",
    "    mag_rms = np.average(np.sqrt((out_point['mag_diff']**2).astype(float)))\n",
    "\n",
    "    return pos_rms, mag_rms, dfs, chi2_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ac08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'SIE_SHEAR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9be7757a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$\\\\sigma$', 'x', 'y', 'e', '$θ_{e}$', '$r_{core}$', 'NaN', '$z_{s,fid}$', 'x', 'y', '$\\\\gamma$', '$θ_{\\\\gamma}$', 'NaN', '$\\\\kappa$']\n"
     ]
    }
   ],
   "source": [
    "num_lenses = model_name.count('_') + 1\n",
    "macro_model_params = model_name.strip().split('_')[0]\n",
    "macro_columns = model_params[macro_model_params]\n",
    "print(macro_columns)\n",
    "\n",
    "for i in range(1, num_lenses):\n",
    "    micro_model_params = model_name.strip().split('_')[i]\n",
    "    if micro_model_params == 'SHEAR':\n",
    "        micro_model_params = 'PERT'\n",
    "    micro_columns = model_params[micro_model_params]\n",
    "    micro_columns = [f'{col}_{i}' for col in micro_columns]\n",
    "\n",
    "if num_lenses == 1:\n",
    "    df = pd.DataFrame(columns=['m', 'n', 'o', 'num_images', 'pos_rms', 'mag_rms', 'chi2'] + macro_columns)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=['m', 'n', 'o', 'num_images', 'pos_rms', 'mag_rms', 'chi2'] + macro_columns + micro_columns)\n",
    "\n",
    "model_ver = model_name\n",
    "\n",
    "if 'POS+FLUX' in model_ver:\n",
    "    constraint = 'pos_flux'\n",
    "elif 'POS' in model_ver:\n",
    "    constraint = 'pos'\n",
    "\n",
    "constraint = 'pos'\n",
    "pos_rms, mag_rms, dfs, chi2 = rms_extract(model_name, '/Users/ainsleylewis/Documents/Astronomy/IllustrisTNG Lens Modelling/SIE+SHEAR/', constraint)\n",
    "if pos_rms == -1: raise IOError(\"rms_extract failed.\")\n",
    "point_file_path = '/Users/ainsleylewis/Documents/Astronomy/IllustrisTNG Lens Modelling/obs_point/obs_point_(POS+FLUX).dat'; num_images = 0\n",
    "if os.path.exists(point_file_path):\n",
    "    with open(point_file_path, 'r') as f: num_images = sum(1 for line in f if line.strip()) - 1\n",
    "\n",
    "\n",
    "# Result dictionary with 'o_param'\n",
    "# Ensure we're only using the first 7 symbols per model (rms_extract uses [:7] when building dfs)\n",
    "macro_cols = list(dict.fromkeys(macro_columns[:7])) if isinstance(macro_columns, list) else [macro_columns]\n",
    "micro_cols = list(dict.fromkeys(micro_columns[:7])) if isinstance(micro_columns, list) else [micro_columns]\n",
    "\n",
    "def _safe_get(dfs_idx, col):\n",
    "    if len(dfs) > dfs_idx and col in dfs[dfs_idx].columns:\n",
    "        return dfs[dfs_idx][col].iloc[0]\n",
    "    return 0\n",
    "\n",
    "result_dict = {\n",
    "    'm': 1,\n",
    "    'n': 1,\n",
    "    'o': 1,\n",
    "    'num_images': num_images,\n",
    "    'pos_rms': pos_rms,\n",
    "    'mag_rms': mag_rms,\n",
    "    'chi2': chi2\n",
    "}\n",
    "\n",
    "# Add macro and micro parameters safely\n",
    "for col in macro_cols:\n",
    "    result_dict[col] = _safe_get(0, col)\n",
    "\n",
    "if num_lenses > 1:\n",
    "    for col in micro_cols:\n",
    "        result_dict[col] = _safe_get(1, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "478c150a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m': 1,\n",
       " 'n': 1,\n",
       " 'o': 1,\n",
       " 'num_images': 4,\n",
       " 'pos_rms': 3.101229586803652e-05,\n",
       " 'mag_rms': 154.45695,\n",
       " 'chi2': 2.242436e-06,\n",
       " '$\\\\sigma$': 156.3051,\n",
       " 'x': 0.0,\n",
       " 'y': 0.0,\n",
       " 'e': 0.2168966,\n",
       " '$θ_{e}$': -1.398259,\n",
       " '$r_{core}$': 0.0,\n",
       " 'NaN': 0.0,\n",
       " '$z_{s,fid}$_1': 0,\n",
       " 'x_1': 0,\n",
       " 'y_1': 0,\n",
       " '$\\\\gamma$_1': 0,\n",
       " '$θ_{\\\\gamma}$_1': 0,\n",
       " 'NaN_1': 0,\n",
       " '$\\\\kappa$_1': 0}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c8bca615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 20.86899, 20.69488]]\n"
     ]
    }
   ],
   "source": [
    "pos_rms, mag_rms, dfs, chi2 = rms_extract(model_name, '/Users/ainsleylewis/Documents/Astronomy/IllustrisTNG Lens Modelling/SIE+SHEAR/', constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc8fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'NFW'\n",
    "model_output_dir = '/Volumes/T7 Shield/Simulations/Output/'\n",
    "temp_input_py_file = '/Volumes/T7 Shield/Simulations/Input/input.py'\n",
    "m_val = 0.5\n",
    "n_val = 0.3\n",
    "o_val = 0.7\n",
    "obs_point_file = '/Users/ainsleylewis/Documents/Astronomy/IllustrisTNG Lens Modelling/obs_point/obs_point_(POS+FLUX).dat' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce4dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_extract(model_ver, model_path, temp_input_py_file):\n",
    "    global pos_rms, mag_rms, chi2_value\n",
    "    \n",
    "    opt_result_file = os.path.join(model_path, f'{model_ver}_optresult.dat')\n",
    "    \n",
    "    with open(opt_result_file, 'r') as file:\n",
    "        opt_result = file.readlines()\n",
    "\n",
    "    last_optimize_index = None\n",
    "    for idx in range(len(opt_result) - 1, -1, -1):\n",
    "        if 'optimize' in opt_result[idx]:\n",
    "            last_optimize_index = idx\n",
    "            break\n",
    "    if last_optimize_index is None:\n",
    "        raise ValueError(\"No line with 'optimize' found in the file.\")\n",
    "\n",
    "    opt_result = opt_result[last_optimize_index + 1:]\n",
    "\n",
    "    lens_params_dict = {}\n",
    "    lens_params = []\n",
    "    for line in opt_result:\n",
    "        if line.startswith('lens'):\n",
    "            parts = re.split(r'\\s+', line.strip())\n",
    "            lens_name = parts[1]\n",
    "            params = [float(x) for x in parts[2:]]\n",
    "            lens_params_dict[lens_name] = params\n",
    "            lens_params.append((lens_name, params))\n",
    "    if lens_params:\n",
    "        for i in range(len(lens_params)):\n",
    "            lens_name, params = lens_params[i]\n",
    "            lens_params_dict[lens_name] = params[1:]\n",
    "\n",
    "    source_params = []\n",
    "    for line in opt_result:\n",
    "        if line.startswith('point'):\n",
    "            parts = re.split(r'\\s+', line.strip())\n",
    "            params = [float(x) for x in parts[1:]]\n",
    "            source_params.append(params)\n",
    "    \n",
    "    chi2_line = next((line for line in opt_result if 'chi^2' in line), None)\n",
    "    if chi2_line is None:\n",
    "        raise ValueError(\"No line with 'chi2' found in the file.\")\n",
    "    chi2_value = float(chi2_line.split('=')[-1].strip().split()[0])\n",
    "    num_lens_profiles = len(lens_params_dict)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    rows = []\n",
    "    max_param_len = 0\n",
    "    for lens_name, params in lens_params_dict.items():\n",
    "        row = {'Lens Name': lens_name}\n",
    "        for i, val in enumerate(params): row[f'param{i+1}'] = val\n",
    "        rows.append(row)\n",
    "        if len(params) > max_param_len: max_param_len = len(params)\n",
    "    columns = ['Lens Name'] + [f'param{i+1}' for i in range(max_param_len)]\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    with open(temp_input_py_file, 'r') as file:\n",
    "        py = file.readlines()\n",
    "\n",
    "    set_lens_lines = [line for line in py if line.startswith('glafic.set_lens(')]\n",
    "    if not set_lens_lines: raise ValueError(\"No lines starting with 'glafic.set_lens(' found in the file.\")\n",
    "    set_lens_params = []\n",
    "    for line in set_lens_lines:\n",
    "        match = re.search(r'set_lens\\((.*?)\\)', line)\n",
    "        if match:\n",
    "            params_str = match.group(1)\n",
    "            params = [param.strip() for param in params_str.split(',')]\n",
    "            set_lens_params.append(params)\n",
    "        else: raise ValueError(f\"No valid parameters found in line: {line.strip()}\")\n",
    "\n",
    "    set_lens_dict = {}\n",
    "    for params in set_lens_params:\n",
    "        if len(params) < 3: raise ValueError(f\"Not enough parameters found in line: {params}\")\n",
    "        lens_name = params[1].strip(\"'\\\"\")\n",
    "        lens_params = [float(x) for x in params[2:]]\n",
    "        set_lens_dict[lens_name] = lens_params\n",
    "    if set_lens_dict:\n",
    "        for lens_name, params in set_lens_dict.items():\n",
    "            set_lens_dict[lens_name] = params[1:]\n",
    "\n",
    "    df_input = pd.DataFrame()\n",
    "    rows_input = []\n",
    "    max_param_len_input = 0\n",
    "    for lens_name, params in set_lens_dict.items():\n",
    "        row = {'Lens Name': lens_name}\n",
    "        for i, val in enumerate(params): row[f'param{i+1}'] = val\n",
    "        rows_input.append(row)\n",
    "        if len(params) > max_param_len_input: max_param_len_input = len(params)\n",
    "    columns_input = ['Lens Name'] + [f'param{i+1}' for i in range(max_param_len_input)]\n",
    "    df_input = pd.DataFrame(rows_input, columns=columns_input)\n",
    "    \n",
    "    set_flag_lines = [line for line in py if line.startswith('glafic.setopt_lens(')]\n",
    "    if not set_flag_lines: raise ValueError(\"No lines starting with 'glafic.setopt_lens(' found in the file.\")\n",
    "    set_flag_params = []\n",
    "    for line in set_flag_lines:\n",
    "        match = re.search(r'setopt_lens\\((.*?)\\)', line)\n",
    "        if match:\n",
    "            params_str = match.group(1)\n",
    "            params = [param.strip() for param in params_str.split(',')]\n",
    "            set_flag_params.append(params)\n",
    "        else: raise ValueError(f\"No valid parameters found in line: {line.strip()}\")\n",
    "    \n",
    "    set_flag_dict = {}\n",
    "    for params in set_flag_params:\n",
    "        if len(params) < 2: raise ValueError(f\"Not enough parameters found in line: {params}\")\n",
    "        lens_index = params[0].strip(\"'\\\"\")\n",
    "        lens_name = None\n",
    "        for lens_params in set_lens_params:\n",
    "            if lens_params[0].strip(\"'\\\"\") == lens_index:\n",
    "                lens_name = lens_params[1].strip(\"'\\\"\")\n",
    "                break\n",
    "        if lens_name is None: raise ValueError(f\"Lens name for index {lens_index} not found\")\n",
    "        flag = ','.join(params[1:])\n",
    "        set_flag_dict[lens_name] = flag\n",
    "    if set_flag_dict:\n",
    "        for lens_name, flag in set_flag_dict.items():\n",
    "            flag_parts = flag.split(',')\n",
    "            set_flag_dict[lens_name] = ','.join(flag_parts[1:])\n",
    "    \n",
    "    df_flag = pd.DataFrame()\n",
    "    rows_flag = []\n",
    "    max_flag_len = 0\n",
    "    for flag in set_flag_dict.values():\n",
    "        flag_parts = flag.split(',')\n",
    "        if len(flag_parts) > max_flag_len: max_flag_len = len(flag_parts)\n",
    "    for lens_name, flag in set_flag_dict.items():\n",
    "        flag_parts = flag.split(',')\n",
    "        row = {'Lens Name': lens_name}\n",
    "        for i, val in enumerate(flag_parts): row[f'flag{i+1}'] = val\n",
    "        rows_flag.append(row)\n",
    "    columns_flag = ['Lens Name'] + [f'flag{i+1}' for i in range(max_flag_len)]  \n",
    "    df_flag = pd.DataFrame(rows_flag, columns=columns_flag)\n",
    "    \n",
    "    dfs = []\n",
    "    for i in range(num_lens_profiles):\n",
    "        lens_name = df['Lens Name'][i]\n",
    "        model_type = None\n",
    "        for m_model in model_list:\n",
    "            if m_model.lower() == lens_name.lower():\n",
    "                model_type = m_model\n",
    "                break\n",
    "        if model_type is None: continue\n",
    "        symbols = model_params[model_type][:7]\n",
    "        row_input = pd.DataFrame([df_input.iloc[i, 1:8].values], columns=symbols)\n",
    "        row_output = pd.DataFrame([df.iloc[i, 1:8].values], columns=symbols)\n",
    "        row_flags = pd.DataFrame([df_flag.iloc[i, 1:8].values], columns=symbols)\n",
    "        lens_df = pd.concat([row_input.assign(Type='Input'), row_output.assign(Type='Output'), row_flags.assign(Type='Flag')], ignore_index=True)\n",
    "        lens_df.insert(0, 'Lens Name', lens_name)\n",
    "        cols = lens_df.columns.tolist()\n",
    "        cols.insert(1, cols.pop(cols.index('Type')))\n",
    "        lens_df = lens_df[cols]\n",
    "        dfs.append(lens_df)\n",
    "    \n",
    "    columnn_names = ['x', 'y', 'mag', 'pos_err', 'mag_err', '1', '2', '3']\n",
    "    obs_point = pd.read_csv(obs_point_file, sep='\\s+', header=None, skiprows=1, names=columnn_names)\n",
    "    \n",
    "    out_point_file = os.path.join(model_path, f'{model_ver}_point.dat')\n",
    "    out_point = pd.read_csv(out_point_file, sep='\\s+', header=None, skiprows=1, names=columnn_names)\n",
    "\n",
    "    out_point.drop(columns=['mag_err', '1', '2', '3'], inplace=True)\n",
    "    mask = abs(out_point['mag']) >= 1\n",
    "    out_point = out_point[mask[:len(out_point)]].reset_index(drop=True)\n",
    "    out_point['x_diff'] = abs(out_point['x'] - obs_point['x'])\n",
    "    out_point['y_diff'] = abs(out_point['y'] - obs_point['y'])\n",
    "    out_point['mag_diff'] = abs(abs(out_point['mag']) - abs(obs_point['mag']))\n",
    "    out_point['pos_sq'] = np.sqrt((out_point['x_diff']**2 + out_point['y_diff']**2).astype(float))\n",
    "    pos_rms = np.average(out_point['pos_sq'])\n",
    "    mag_rms = np.average(np.sqrt((out_point['mag_diff']**2).astype(float)))\n",
    "    return pos_rms, mag_rms, dfs, chi2_value, source_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcbbde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rms, mag_rms, dfs, chi2, source = rms_extract(model_name, model_output_dir, temp_input_py_file)\n",
    "if pos_rms == -1: raise IOError(\"rms_extract failed.\")\n",
    "\n",
    "num_images = 0\n",
    "out_point_file = os.path.join(model_output_dir, f'{model_name}_point.dat')\n",
    "if os.path.exists(out_point_file):\n",
    "    with open(out_point_file, 'r') as f: num_images = sum(1 for line in f if line.strip()) - 1\n",
    "    \n",
    "result_dict = {\n",
    "    'm': m_val, 'n': n_val, 'o': o_val, \n",
    "    'num_images': num_images, 'pos_rms': pos_rms, \n",
    "    'mag_rms': mag_rms, 'chi2': chi2\n",
    "}\n",
    "\n",
    "num_lenses = model_name.count('_') - 2\n",
    "macro_model_params = model_name.strip().split('_')[0]\n",
    "if macro_model_params == 'NFW': \n",
    "    macro_model_params = 'ANFW'\n",
    "macro_columns = model_params[macro_model_params]\n",
    "\n",
    "if num_lenses > 1:\n",
    "    for i in range(1, num_lenses):\n",
    "        micro_model_params = model_name.strip().split('_')[i]\n",
    "        if micro_model_params == 'SHEAR': micro_model_params = 'PERT'\n",
    "        micro_columns = model_params[micro_model_params]\n",
    "        micro_columns = [f'{col}_{i}' for col in micro_columns]\n",
    "\n",
    "macro_cols = list(dict.fromkeys(macro_columns[:7])) if isinstance(macro_columns, list) else [macro_columns]\n",
    "if num_lenses > 1:\n",
    "    micro_cols = list(dict.fromkeys(micro_columns[:7])) if isinstance(micro_columns, list) else [micro_columns]\n",
    "\n",
    "def _safe_get(dfs_idx, col):\n",
    "    if len(dfs) > dfs_idx and col in dfs[dfs_idx].columns:\n",
    "        return dfs[dfs_idx][col].iloc[1]\n",
    "    return 0\n",
    "\n",
    "for col in macro_cols: result_dict[col] = _safe_get(0, col)\n",
    "if num_lenses > 1:\n",
    "    for len_num in range(1, num_lenses):\n",
    "        for col in micro_cols:\n",
    "            stripped_col = col.strip(f'_{len_num}')\n",
    "            result_dict[col] = _safe_get(1, stripped_col)\n",
    "\n",
    "result_dict['source_x'] = source[0][1] if source and len(source) > 0 else 0\n",
    "result_dict['source_y'] = source[0][2] if source and len(source) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d936dec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m': 0.5,\n",
       " 'n': 0.3,\n",
       " 'o': 0.7,\n",
       " 'num_images': 5,\n",
       " 'pos_rms': 0.5206431707220018,\n",
       " 'mag_rms': 18.6125,\n",
       " 'chi2': 108000.1,\n",
       " 'M': 1877439000000.0,\n",
       " 'x': 20.86964,\n",
       " 'y': 20.94406,\n",
       " 'e': 0.107,\n",
       " '$θ_{e}$': 23.38,\n",
       " 'c or $r_{s}$': 20.0,\n",
       " 'NaN': 0.0,\n",
       " 'source_x': 20.86232,\n",
       " 'source_y': 20.94153}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
