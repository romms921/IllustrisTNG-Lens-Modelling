{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.colors import LogNorm\n",
    "from astropy.visualization import SqrtStretch, LinearStretch, LogStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "import pandas as pd\n",
    "import re\n",
    "from astropy.io import fits\n",
    "import os\n",
    "import subprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to process a single model (normal or shear)\n",
    "def _process_single_model(model_path, model_ver, obs_coords):\n",
    "    \"\"\"\n",
    "    Processes a single lens model, runs glafic, and extracts results.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the model directory (e.g., 'NFW', 'NFW+SHEAR').\n",
    "        model_ver (str): Specific version/run name (e.g., 'NFW_POS+FLUX', 'NFW_POS+FLUX_SHEAR').\n",
    "        obs_coords (pd.DataFrame): DataFrame with observed positions ('x', 'y') already transformed for plotting.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Contains:\n",
    "            - kappa (np.ndarray): The kappa map data.\n",
    "            - pred (pd.DataFrame): DataFrame with predicted positions and transformed coords ('x_plot', 'y_plot').\n",
    "            - model_ver (str): The input model version string (for titles).\n",
    "            - is_shear (bool): Flag indicating if the model included shear.\n",
    "    \"\"\"\n",
    "    print(f\"--- Processing Model: {model_ver} ---\")\n",
    "\n",
    "    is_shear = 'SHEAR' in model_path.upper()\n",
    "\n",
    "    # --- Determine Constraint Type ---\n",
    "    if 'POS+FLUX' in model_ver:\n",
    "        constraint = 'pos_flux'\n",
    "    elif 'POS' in model_ver:\n",
    "        constraint = 'pos'\n",
    "    else:\n",
    "        # Fallback or raise error if constraint type is unclear\n",
    "        print(f\"Warning: Could not determine constraint type for {model_ver}. Assuming 'pos'.\")\n",
    "        constraint = 'pos' # Or raise ValueError(\"Cannot determine constraint type\")\n",
    "\n",
    "    # --- File Paths ---\n",
    "    optresult_file = os.path.join(model_path, f\"{model_ver}_optresult.dat\")\n",
    "    # point_py_file = os.path.join(model_path, f\"{constraint}_point.py\") # Not strictly needed for kappa run\n",
    "    pred_point_dat_file = os.path.join(model_path, f\"{model_ver}_point.dat\")\n",
    "    kappa_base_path = os.path.join('Kappa', model_path, model_ver)\n",
    "    kappa_fits_file = os.path.join('Kappa', model_path, f\"{model_ver}_lens.fits\")\n",
    "    glafic_output_name = f\"'Kappa/{model_path}/{model_ver}'\" # Name used inside glafic script\n",
    "\n",
    "    # --- Read Optimization Results ---\n",
    "    try:\n",
    "        with open(optresult_file, 'r') as file:\n",
    "            opt_result = file.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Optimization result file not found: {optresult_file}\")\n",
    "        return None, None, model_ver, is_shear # Return None if file missing\n",
    "\n",
    "    # --- Extract Lens Parameters ---\n",
    "    lens_params = {}\n",
    "    model_input_map = {} # To store mapping like 1 -> 'sie', 2 -> 'pert'\n",
    "\n",
    "    # Determine primary lens model name\n",
    "    model_input_1_name_raw = model_path.lower().replace('+shear', '') # Get base model name\n",
    "    if 'nfw' in model_input_1_name_raw:\n",
    "        model_input_1_name = 'anfw'\n",
    "    elif 'c_sie' in model_input_1_name_raw:\n",
    "        model_input_1_name = 'sie'\n",
    "    elif 'sie' in model_input_1_name_raw:\n",
    "         model_input_1_name = 'sie'\n",
    "    elif 'pow' in model_input_1_name_raw:\n",
    "         model_input_1_name = 'pow'\n",
    "    elif 'ein' in model_input_1_name_raw:\n",
    "         model_input_1_name = 'ein'\n",
    "    else:\n",
    "        # Add more mappings or a default/error\n",
    "        print(f\"Warning: Unknown primary lens type in {model_path}. Add mapping.\")\n",
    "        model_input_1_name = model_input_1_name_raw # Use raw name as fallback\n",
    "\n",
    "    model_input_map[1] = model_input_1_name\n",
    "    try:\n",
    "        lens_line_1 = next(line for line in reversed(opt_result) if f'lens   {model_input_1_name}' in line)\n",
    "        lens_params[1] = lens_line_1.split()[2:]\n",
    "        print(f\"Found primary lens params ({model_input_1_name}): {lens_params[1]}\")\n",
    "    except StopIteration:\n",
    "        print(f\"Error: Could not find lens parameters for '{model_input_1_name}' in {optresult_file}\")\n",
    "        return None, None, model_ver, is_shear\n",
    "\n",
    "    # Extract shear parameters if needed\n",
    "    if is_shear:\n",
    "        model_input_2_name = 'pert'\n",
    "        model_input_map[2] = model_input_2_name\n",
    "        try:\n",
    "            lens_line_2 = next(line for line in reversed(opt_result) if f'lens   {model_input_2_name}' in line)\n",
    "            lens_params[2] = lens_line_2.split()[2:]\n",
    "            print(f\"Found shear lens params ({model_input_2_name}): {lens_params[2]}\")\n",
    "        except StopIteration:\n",
    "            print(f\"Error: Could not find lens parameters for '{model_input_2_name}' (shear) in {optresult_file}\")\n",
    "            # Decide if this is fatal or if we proceed without shear\n",
    "            return None, None, model_ver, is_shear\n",
    "\n",
    "    # Extract Source Position\n",
    "    try:\n",
    "        set_point_line = next(line for line in reversed(opt_result) if 'point' in line)\n",
    "        set_point_values = set_point_line.split()[1:]\n",
    "        print(f\"Found source position params: {set_point_values}\")\n",
    "        if len(set_point_values) != 3:\n",
    "             raise ValueError(f\"Expected 3 values for point source, found {len(set_point_values)}\")\n",
    "    except (StopIteration, ValueError) as e:\n",
    "        print(f\"Error: Could not find or parse source position ('point') in {optresult_file}: {e}\")\n",
    "        return None, None, model_ver, is_shear\n",
    "\n",
    "    # --- Prepare and Run Glafic ---\n",
    "    # Create output directory\n",
    "    os.makedirs(os.path.dirname(kappa_base_path), exist_ok=True)\n",
    "    # Create the placeholder file glafic needs to write to (optional, glafic might create it)\n",
    "    # with open(kappa_base_path, 'w') as f: pass # Ensure file path exists\n",
    "\n",
    "    # Choose and modify the correct glafic template script\n",
    "    glafic_template_file = 'kappa_shear_glafic.py' if is_shear else 'kappa_glafic.py'\n",
    "    glafic_run_script = f\"run_glafic_{model_ver}.py\" # Use a temporary script name\n",
    "\n",
    "    try:\n",
    "        with open(glafic_template_file, 'r') as f_template:\n",
    "            glafic_script_lines = f_template.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Glafic template script not found: {glafic_template_file}\")\n",
    "        return None, None, model_ver, is_shear\n",
    "\n",
    "    # Modify the script content\n",
    "    updated_glafic_script = []\n",
    "    for line in glafic_script_lines:\n",
    "        if 'glafic.set_lens(1,' in line or (not is_shear and 'glafic.set_lens(' in line):\n",
    "             # Modify the first (or only) lens component\n",
    "             params_str = \", \".join(map(str, lens_params[1]))\n",
    "             line = f\"glafic.set_lens(1, '{model_input_map[1]}', {params_str})\\n\"\n",
    "             print(f\"Updated line: {line.strip()}\")\n",
    "        elif is_shear and 'glafic.set_lens(2,' in line:\n",
    "             # Modify the second lens component (shear)\n",
    "             params_str = \", \".join(map(str, lens_params[2]))\n",
    "             line = f\"glafic.set_lens(2, '{model_input_map[2]}', {params_str})\\n\"\n",
    "             print(f\"Updated line: {line.strip()}\")\n",
    "        elif 'glafic.init(' in line:\n",
    "            # Update output file name and other potential params\n",
    "            # Keeping other init params fixed as in the original scripts\n",
    "            line = f\"glafic.init(0.3, 0.7, -1.0, 0.7, {glafic_output_name}, 20.0, 20.0, 21.56, 21.56, 0.001, 0.001, 1, verb = 0)\\n\"\n",
    "            print(f\"Updated line: {line.strip()}\")\n",
    "        elif 'glafic.set_point(' in line:\n",
    "            # Update source position\n",
    "            line = f\"glafic.set_point(1, {set_point_values[0]}, {set_point_values[1]}, {set_point_values[2]})\\n\" # Assuming format is ID, z, x, y\n",
    "            print(f\"Updated line: {line.strip()}\")\n",
    "\n",
    "        updated_glafic_script.append(line)\n",
    "\n",
    "    # Write the modified script to a temporary file\n",
    "    try:\n",
    "        with open(glafic_run_script, 'w') as f_run:\n",
    "            f_run.writelines(updated_glafic_script)\n",
    "\n",
    "        # Run the glafic script using subprocess\n",
    "        print(f\"Running glafic script: {glafic_run_script}...\")\n",
    "        # Use sys.executable to ensure using the correct python interpreter\n",
    "        # result = subprocess.run([sys.executable, glafic_run_script], capture_output=True, text=True, check=True)\n",
    "        # print(\"Glafic stdout:\", result.stdout)\n",
    "        # print(\"Glafic stderr:\", result.stderr)\n",
    "        # Using %run magic command for compatibility with the original script's environment (e.g., Jupyter)\n",
    "        # Note: This requires the code to be run in an IPython/Jupyter environment.\n",
    "        # If running as a standard Python script, switch to subprocess.\n",
    "        ipython = get_ipython()\n",
    "        ipython.run_cell(f\"%run {glafic_run_script}\")\n",
    "        print(\"Glafic script finished.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running glafic script {glafic_run_script}: {e}\")\n",
    "        # Consider cleaning up the temporary script file\n",
    "        # if os.path.exists(glafic_run_script): os.remove(glafic_run_script)\n",
    "        return None, None, model_ver, is_shear\n",
    "    finally:\n",
    "        # Clean up the temporary glafic script\n",
    "        if os.path.exists(glafic_run_script):\n",
    "             os.remove(glafic_run_script)\n",
    "             print(f\"Removed temporary script: {glafic_run_script}\")\n",
    "\n",
    "\n",
    "    # --- Read Predicted Positions ---\n",
    "    try:\n",
    "        pred_columns = ['x', 'y', 'mag', 'delay', 'parity'] # Adjust if columns differ\n",
    "        # Use sep='\\s+' for flexible whitespace separation\n",
    "        pred = pd.read_csv(pred_point_dat_file, sep='\\s+', header=None, skiprows=1, names=pred_columns, comment='#')\n",
    "        # Apply coordinate transformation (same as for observed)\n",
    "        pred['x_plot'] = (pred['x'] - 20) / 0.001\n",
    "        pred['y_plot'] = (pred['y'] - 20) / 0.001\n",
    "        print(f\"Loaded {len(pred)} predicted positions from {pred_point_dat_file}\")\n",
    "\n",
    "        # Optional: Remove 5th image for shear models (if needed)\n",
    "        # This logic might need adjustment based on how the 5th image is identified\n",
    "        if is_shear and len(pred) > 4:\n",
    "             print('Potentially removing 5th image (lowest magnification)')\n",
    "             # Find index of image with minimum absolute magnification\n",
    "             # Ensure 'mag' column is numeric\n",
    "             pred['mag'] = pd.to_numeric(pred['mag'])\n",
    "             lowest_mag_index = pred['mag'].abs().idxmin()\n",
    "             print(f\"Removing image at index {lowest_mag_index} with mag {pred.loc[lowest_mag_index, 'mag']}\")\n",
    "             pred = pred.drop(lowest_mag_index).reset_index(drop=True)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Predicted positions file not found: {pred_point_dat_file}\")\n",
    "        return None, None, model_ver, is_shear\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing predicted positions file {pred_point_dat_file}: {e}\")\n",
    "        return None, None, model_ver, is_shear\n",
    "\n",
    "\n",
    "    # --- Read Kappa FITS File ---\n",
    "    try:\n",
    "        with fits.open(kappa_fits_file) as hdu_list:\n",
    "            # Assuming kappa is in the 4th extension (index 3) based on original script\n",
    "            # Verify this structure if glafic output changes\n",
    "            if len(hdu_list[0].data) > 3:\n",
    "                 kappa = np.array(hdu_list[0].data[3])\n",
    "                 print(f\"Loaded kappa map (shape: {kappa.shape}) from {kappa_fits_file}\")\n",
    "            else:\n",
    "                 print(f\"Error: Expected at least 4 data arrays in HDU 0 of {kappa_fits_file}, found {len(hdu_list[0].data)}\")\n",
    "                 return None, pred, model_ver, is_shear # Return pred data even if kappa fails\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Kappa FITS file not found: {kappa_fits_file}\")\n",
    "        # Still return prediction data if available\n",
    "        return None, pred, model_ver, is_shear\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading kappa FITS file {kappa_fits_file}: {e}\")\n",
    "        return None, pred, model_ver, is_shear\n",
    "\n",
    "    print(f\"--- Finished Processing: {model_ver} ---\")\n",
    "    return kappa, pred, model_ver, is_shear\n",
    "\n",
    "\n",
    "# Main comparison function\n",
    "def compare_models(model_path_1, model_ver_1, model_path_2, model_ver_2):\n",
    "    \"\"\"\n",
    "    Compares two lens models (normal or shear) side-by-side by plotting their\n",
    "    kappa maps and overlaying observed/predicted image positions.\n",
    "\n",
    "    Args:\n",
    "        model_path_1 (str): Path for model 1 (e.g., 'NFW', 'NFW+SHEAR').\n",
    "        model_ver_1 (str): Version/run name for model 1 (e.g., 'NFW_POS+FLUX').\n",
    "        model_path_2 (str): Path for model 2.\n",
    "        model_ver_2 (str): Version/run name for model 2.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Load Observed Positions (once) ---\n",
    "    obs_file = 'obs_point/obs_point_(POS+FLUX).dat'\n",
    "    try:\n",
    "        obs = pd.read_fwf(obs_file, header=None, names=['x', 'y', 'm', 'pos_err', 'm_err', 'ex1', 'ex2'], skiprows=1)\n",
    "        plot_obs = obs[['x', 'y', 'm']].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "        # Apply coordinate transformation\n",
    "        plot_obs['x'] = (plot_obs['x'] - 20) / 0.001\n",
    "        plot_obs['y'] = (plot_obs['y'] - 20) / 0.001\n",
    "        print(f\"Loaded {len(plot_obs)} observed positions from {obs_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Observed positions file not found: {obs_file}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing observed positions file {obs_file}: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Process Each Model ---\n",
    "    results = {}\n",
    "    models_to_process = {\n",
    "        1: (model_path_1, model_ver_1),\n",
    "        2: (model_path_2, model_ver_2)\n",
    "    }\n",
    "\n",
    "    for i, (m_path, m_ver) in models_to_process.items():\n",
    "        kappa, pred, _, is_shear_flag = _process_single_model(m_path, m_ver, plot_obs)\n",
    "        if kappa is not None and pred is not None:\n",
    "            results[i] = {'kappa': kappa, 'pred': pred, 'ver': m_ver, 'is_shear': is_shear_flag}\n",
    "        else:\n",
    "            print(f\"Failed to process model {i} ({m_ver}). Skipping plot for this model.\")\n",
    "            results[i] = None # Mark as failed\n",
    "\n",
    "\n",
    "    # --- Plotting ---\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(22, 10), sharex=True, sharey=True) # Increased size slightly\n",
    "    axs = axs.flatten() # Ensure axs is always iterable\n",
    "\n",
    "    plot_titles = {1: model_ver_1, 2: model_ver_2}\n",
    "    plot_successful = [False, False]\n",
    "\n",
    "    for i in range(1, 3):\n",
    "        ax = axs[i-1]\n",
    "        res = results.get(i)\n",
    "\n",
    "        if res:\n",
    "            kappa = res['kappa']\n",
    "            pred = res['pred']\n",
    "            ver = res['ver']\n",
    "\n",
    "            try:\n",
    "                # Normalize kappa map using LogStretch\n",
    "                # Add a small epsilon if kappa can be zero or negative\n",
    "                kappa_min_safe = np.min(kappa[kappa > 0]) if np.any(kappa > 0) else 1e-9\n",
    "                norm = ImageNormalize(kappa, vmin=kappa_min_safe, stretch=LogStretch(a=1000)) # Adjust 'a' if needed\n",
    "\n",
    "                im = ax.imshow(kappa, cmap='hot', norm=norm, origin='lower',\n",
    "                               extent=[0, kappa.shape[1], 0, kappa.shape[0]]) # Use extent for coord matching\n",
    "                # ax.invert_yaxis() # origin='lower' handles this\n",
    "\n",
    "                # Logarithmic levels for contours\n",
    "                kappa_min_log = max(kappa.min(), 1e-6) # Avoid log(0 or negative)\n",
    "                levels = np.logspace(np.log10(kappa_min_log), np.log10(kappa.max()), 15) # Reduced levels\n",
    "                contour = ax.contour(\n",
    "                    kappa,\n",
    "                    levels=levels,\n",
    "                    colors='cyan',\n",
    "                    linewidths=1.0,\n",
    "                    linestyles='dashed',\n",
    "                    alpha=1,\n",
    "                    extent=[0, kappa.shape[1], 0, kappa.shape[0]], # Match imshow extent\n",
    "                )\n",
    "\n",
    "                # Plot predicted and observed positions\n",
    "                # Ensure plot coordinates match the imshow/contour extent\n",
    "                ax.scatter(plot_obs['x'], plot_obs['y'], s=70, label='Observed', marker='o', alpha=1)\n",
    "                ax.scatter(pred['x_plot'], pred['y_plot'], c='white', s=90, label='Predicted', marker='x', alpha=1)\n",
    "\n",
    "                ax.set_title(f'Model: {ver}')\n",
    "                ax.legend()\n",
    "                ax.set_xlabel('X (pixels)')\n",
    "                ax.set_ylabel('Y (pixels)')\n",
    "                ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "                cbar = fig.colorbar(im, ax=ax, label=r'$\\kappa$') # Added shrink\n",
    "                cbar.set_label(r'$\\kappa$', rotation=0, labelpad=15, fontsize=12)\n",
    "                plot_successful[i-1] = True\n",
    "\n",
    "            except Exception as plot_err:\n",
    "                 print(f\"Error plotting model {i} ({ver}): {plot_err}\")\n",
    "                 ax.set_title(f'Model: {ver}\\n(Plotting Failed)')\n",
    "                 ax.text(0.5, 0.5, 'Plotting Error', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "        else:\n",
    "            # Handle case where model processing failed\n",
    "            ax.set_title(f'Model: {plot_titles[i]}\\n(Processing Failed)')\n",
    "            ax.text(0.5, 0.5, 'Processing Error', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "            ax.set_xlabel('X (pixels)')\n",
    "            ax.set_ylabel('Y (pixels)')\n",
    "\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Add rect to prevent title overlap with suptitle if added\n",
    "    # Add overall title if desired\n",
    "    # fig.suptitle(\"Lens Model Comparison\", fontsize=16)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
